{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8181bb6-bcd8-47e6-9746-bf3ceb3f44f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# add paths for modules\n",
    "sys.path.append('../visualization')\n",
    "sys.path.append('../features')\n",
    "sys.path.append('../models')\n",
    "sys.path.append('../datawrangling')\n",
    "from maritime_traffic_network import MaritimeTrafficNetwork\n",
    "import dataloader_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40c6ffc9-ee7e-438b-a398-cb5fb10dae70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Data': '../../data/processed/202204_points_tromso_cleaned_meta_full_dualSplit_2.parquet',\n",
       " 'DP_tolerance': 10,\n",
       " 'clustering_method': 'HDBSCAN',\n",
       " 'clustering_metric': 'mahalanobis',\n",
       " 'clustering_min_samples': 13,\n",
       " 'clustering_min_cluster_size': 13,\n",
       " 'clustering_eps': 0,\n",
       " 'clustering_metric_V': array([[1.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 1.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.01, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.01, 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  , 1.  ]]),\n",
       " 'graph_generation_max_distance': 20,\n",
       " 'graph_generation_max_angle': 45}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a model from pickle\n",
    "datasize = 'full'\n",
    "location = 'tromso'\n",
    "network_date = '202204'\n",
    "train_dates = ['202205']\n",
    "DP_tol = 10\n",
    "min_samples = 13\n",
    "\n",
    "network_name = network_date+'_waypoints_DP'+str(DP_tol)+'_HDBSCAN'+str(min_samples)+'_'+location+'_'+datasize+'_UTM'\n",
    "network_path = '../../models/networks/best_networks/' + network_name + '.obj'\n",
    "fileObj = open(network_path, 'rb')\n",
    "network = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "network.hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c494af-4816-4350-bfd4-44551d263aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data from file\n",
    "path_prefix = '../../data/paths/'\n",
    "training_paths = dataloader_paths.load_path_training_data(path_prefix, network_name, train_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88701a68-5503-4045-924e-354c11048501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# destination_path\n",
    "dest_path = '../../data/interim/gretel_input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07004b11-54bc-4cb3-864b-25c619609413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write graph to files 'nodes.txt', 'edges.txt'\n",
    "G = network.G.copy()\n",
    "\n",
    "# drop some node features\n",
    "for node, data in G.nodes(data=True):\n",
    "    if 'position' in data:\n",
    "        #lat, lon = data['position']\n",
    "        #data['lat'] = lat\n",
    "        #data['lon'] = lon\n",
    "        del data['position']\n",
    "    del data['cog_before']\n",
    "    del data['cog_after']\n",
    "    del data['speed']\n",
    "\n",
    "# write nodes to file\n",
    "with open(os.path.join(dest_path, 'nodes.txt'), 'w') as f:\n",
    "    f.write(\"{}\\t{}\\n\".format(\n",
    "        G.number_of_nodes(), 0 if G.nodes is None else len(G.nodes[0])))\n",
    "    if G.nodes is not None:\n",
    "        for i, (id, features) in enumerate(G.nodes.data()):\n",
    "            line = str(id) + \"\\t\" + \"\\t\".join(\n",
    "                map(str, [val for key, val in features.items()])) + \"\\n\"\n",
    "            f.write(line)\n",
    "\n",
    "# rearrange edge features\n",
    "edges = G.edges\n",
    "unique_edge_features = set()\n",
    "for i, (sender, receiver, features) in enumerate(edges.data()):\n",
    "    del edges[sender, receiver]['geometry']\n",
    "    del edges[sender, receiver]['inverse_weight']\n",
    "    #del edges[sender, receiver]['length']\n",
    "    #del edges[sender, receiver]['direction']\n",
    "    unique_edge_features.update(features.keys())\n",
    "n_edge_features = len(unique_edge_features)\n",
    "\n",
    "edge_dict = {}  # dictionary mapping edge ID to sender and receiver node\n",
    "with open(os.path.join(dest_path, 'edges.txt'), 'w') as f:\n",
    "    f.write(\"{}\\t{}\\n\".format(\n",
    "        G.number_of_edges(), 0 if edges is None else n_edge_features))\n",
    "    for i, (sender, receiver, features) in enumerate(edges.data()):\n",
    "        line = \"\\t\".join(map(str, [i, sender, receiver])) + \\\n",
    "               \"\\t\" + \\\n",
    "               \"\\t\".join(map(str, [val for key, val in features.items()])) + \"\\n\"\n",
    "        f.write(line)\n",
    "        edge_dict[(sender, receiver)] = i  # save id for later mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a1eb22-6b82-4cc8-96b5-0fdc0ecb6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write path data to files 'lengths.txt', 'observations.txt', 'paths.txt'\n",
    "mode = 'start2target' #'node2node' #'start2target'\n",
    "#training_paths = training_paths[0:200]\n",
    "\n",
    "if mode == 'start2target':\n",
    "    # write path lengths to file 'lengths.txt'\n",
    "    # in this case, path length is always 2, directly from start observation to target observation\n",
    "    with open(os.path.join(dest_path, \"lengths.txt\"), \"w\") as f:\n",
    "        for i, l in enumerate(training_paths):\n",
    "            f.write(\"{}\\t{}\\n\".format(i, 2))\n",
    "    \n",
    "    # write observations to file 'observations.txt'\n",
    "    # for each path, we have 2 observations: start observation and target target observation, which each get their own line\n",
    "    # the value 1 denotes the probability of this observation (peculiarity of gretel)\n",
    "    with open(os.path.join(dest_path, \"observations.txt\"), \"w\") as f:\n",
    "        f.write(\"{}\\t{}\\n\".format(2*len(training_paths), 1))\n",
    "        for path in training_paths:\n",
    "            f.write(\"{}\\t{}\\n\".format(path[0], 1.0))\n",
    "            f.write(\"{}\\t{}\\n\".format(path[-1], 1.0))\n",
    "\n",
    "    # write edge sequence to file 'path.txt'\n",
    "    # we need to convert the sequence of node ids to a sequence of edge ids\n",
    "    with open(os.path.join(dest_path, \"paths.txt\"), \"w\") as f:\n",
    "        f.write(\"{}\\t{}\\n\".format(len(training_paths), max(len(path) for path in training_paths)))\n",
    "        for path in training_paths:\n",
    "            for i in range(0, len(path)-1):\n",
    "                orig_dest = (path[i], path[i+1])\n",
    "                edge_id = edge_dict[orig_dest]\n",
    "                f.write(\"{}\\t\".format(edge_id))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "if mode == 'node2node':\n",
    "    # write path lengths to file 'lengths.txt'\n",
    "    all_observations=0  # count the number of observations for later\n",
    "    with open(os.path.join(dest_path, \"lengths.txt\"), \"w\") as f:\n",
    "        for i, path in enumerate(training_paths):\n",
    "            f.write(\"{}\\t{}\\n\".format(i, len(path)))\n",
    "            all_observations += len(path)  # count the number of observations for later\n",
    "    \n",
    "    # write observations to file 'observations.txt'\n",
    "    # for each path, we have len(path) observations\n",
    "    # the value 1 denotes the probability of this observation (peculiarity of gretel)\n",
    "    with open(os.path.join(dest_path, \"observations.txt\"), \"w\") as f:\n",
    "        f.write(\"{}\\t{}\\n\".format(all_observations, 1))\n",
    "        for path in training_paths:\n",
    "            for node in path:\n",
    "                f.write(\"{}\\t{}\\n\".format(node, 1.0))\n",
    "\n",
    "    # write edge between each node pair to file 'path.txt'\n",
    "    # we need to convert the sequence of node ids to a sequence of edge ids\n",
    "    with open(os.path.join(dest_path, \"paths.txt\"), \"w\") as f:\n",
    "        f.write(\"{}\\t{}\\n\".format(all_observations - len(training_paths), 1))\n",
    "        for path in training_paths:\n",
    "            for i in range(0, len(path)-1):\n",
    "                orig_dest = (path[i], path[i+1])\n",
    "                edge_id = edge_dict[orig_dest]\n",
    "                f.write(\"{}\\n\".format(edge_id))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edc0e2dc-cc22-4886-9650-c462f14a4b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geometry_utils import is_valid_path\n",
    "for path in training_paths:\n",
    "    if is_valid_path(G, path) == False:\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7e1395b-4e78-48d5-a315-cdf90498c13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(path) for path in training_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1b5a104-05d3-46fa-a846-a4a79386e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save metadata to file\n",
    "node_features = list(G.nodes(data=True))[0][1]\n",
    "\n",
    "meta_dict = {'network_name': network_name,\n",
    "             'n_points': len(network.gdf),\n",
    "             'n_nodes': network.G.number_of_nodes(),\n",
    "             'n_edges': network.G.number_of_edges(),\n",
    "             'training_dates': str(train_dates),\n",
    "             'n_training_paths': len(training_paths),\n",
    "             'node_features': str(list(node_features)),\n",
    "             'egde_features': str(list(unique_edge_features)),\n",
    "             'path_format': mode}\n",
    "with open(dest_path+'metadata.json', 'w') as json_file:\n",
    "    json.dump(meta_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d84b8-4656-4368-afb1-40fa1790dc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc386a5-7fc4-414c-9234-37d66c59ff89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
