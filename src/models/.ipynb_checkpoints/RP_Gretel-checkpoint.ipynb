{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080ed61d-5e01-4ac5-ac13-70918a9bbf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook uses a GRETEL model for route prediction with or without target information.\n",
    "- NOTE: Prediction and evaluation is performed in two separate notebooks. This notebook is for prediction and needs to run in a pytorch-geometric environment (env_pyg)\n",
    "- The input for model training needs to be formatted in a specific way. The notebook DATA_preprocess_for_GRETEL.ipynb takes care of that.\n",
    "- GRETEL uses a specially formatted config file where the user can specify model hyperparameters and filepaths to the training data (more details in the train method of the Gretel class)\n",
    "- specify test data to evaluate the prediction model\n",
    "- specify parameters for prediction\n",
    "The notebook will train the prediction model, make predictions, and save the results to file\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd3175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ast import literal_eval\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append('../datawrangling')\n",
    "\n",
    "# import modules\n",
    "import dataloader_paths\n",
    "from Gretel_path_prediction import GretelPathPrediction\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2608b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path to model\n",
    "load_model = False   # load a pretrained model?\n",
    "directory = '../../models/gretel_prediction_models/oslo_passenger/'\n",
    "path_format = 'node2node'   # format of the training data: 'node2node' (recommended) or 'start2target'\n",
    "\n",
    "# Specify test data\n",
    "test_dates = ['202209']\n",
    "selection_start = 0     # for sampling\n",
    "selection_end = -1      # for sampling\n",
    "selection_step = 20     # for sampling\n",
    "\n",
    "# Specify parameters for prediction\n",
    "prediction_task = 'next_nodes'  # 'next_nodes' (without destination information) or 'path' (with destination information)\n",
    "n_walks = 1000                  # number of random walks for sampling\n",
    "n_start_nodes = 1               # number of observed nodes (defaults to 1)\n",
    "n_steps_vals = [10]             # prediction horizon (only needed for next_nodes prediction)\n",
    "n_predictions = 1               # top n_predictions predictions will be output             \n",
    "max_path_length = 150           # maximum length of the path to be predicted (# of subsequent nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6930ed-0a9d-45cb-99e0-16eee08e463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either load model from file...\n",
    "if load_model:\n",
    "    # load model with pickle\n",
    "    network_name = '202204_waypoints_DP30_HDBSCAN25_stavanger_full_UTM'\n",
    "    model_path = '../../models/gretel_prediction_models/trained_models/'+network_name+'_target.obj'\n",
    "    fileObj = open(model_path, 'rb')\n",
    "    model = pickle.load(fileObj)\n",
    "    fileObj.close()\n",
    "    with open('../../models/gretel_prediction_models/trained_models/metadata_stavanger.json', 'r') as json_file:\n",
    "        meta_dict = json.load(json_file) \n",
    "    data_version = meta_dict['data_version']\n",
    "    print(meta_dict)\n",
    "    \n",
    "# ... or train model from scratch\n",
    "else:\n",
    "    config_file = 'route_target'\n",
    "    task = 'path'\n",
    "    # load metadata file\n",
    "    with open(directory+path_format+'/metadata.json', 'r') as json_file:\n",
    "        meta_dict = json.load(json_file)\n",
    "    network_name = meta_dict['network_name']\n",
    "    data_version = meta_dict['data_version']\n",
    "    filter = meta_dict['filter']\n",
    "    # train model\n",
    "    model = GretelPathPrediction()\n",
    "    model.train(config_file, directory, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34972e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training metrics\n",
    "model.plot_train_test_metrics(test_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc4f2f4-90e5-49d0-8509-f4fed51fe5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data from file\n",
    "path_prefix = '../../data/paths/'\n",
    "all_test_paths = dataloader_paths.load_path_test_data(path_prefix, network_name, test_dates, \n",
    "                                                      0, -1, 1, filter=filter, data_version=data_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b85d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_steps in n_steps_vals:    \n",
    "    # sample test data\n",
    "    if prediction_task == 'next_nodes':\n",
    "        # split test paths in subpaths\n",
    "        sub_paths = dataloader_paths.split_path_data(all_test_paths, n_steps+n_start_nodes)\n",
    "        test_paths = dataloader_paths.sample_path_data(sub_paths, selection_start, selection_end, selection_step)\n",
    "    else:\n",
    "        test_paths = dataloader_paths.sample_path_data(all_test_paths, selection_start, selection_end, selection_step)\n",
    "    n_test_paths=len(test_paths)\n",
    "    \n",
    "    \n",
    "    #### MAKE PREDICTIONS ####\n",
    "    start_time = time.time()\n",
    "    predictions = model.predict(prediction_task, test_paths, n_start_nodes, n_steps, \n",
    "                                n_predictions, n_walks, max_path_length)\n",
    "    end_time = time.time()  # end timer\n",
    "    print(f'Time elapsed: {(end_time-start_time)/60:.2f} minutes')\n",
    "    pps = n_test_paths/(end_time-start_time)\n",
    "    print('Predictions per second: ', pps)\n",
    "    \n",
    "    # save results as csv\n",
    "    predictions.to_csv(directory+path_format+'/predictions_'+prediction_task+str(n_steps)+'.csv')\n",
    "    \n",
    "    # save metadata to file\n",
    "    if load_model == False:\n",
    "        meta_dict['lr'] = model.config.lr\n",
    "        meta_dict['loss'] = model.config.loss\n",
    "        meta_dict['n_epochs'] = model.config.number_epoch\n",
    "        meta_dict['target_prediction'] = model.config.target_prediction\n",
    "    meta_dict['n_walks'] = n_walks\n",
    "    meta_dict['n_start_nodes'] = n_start_nodes\n",
    "    meta_dict['n_steps'] = n_steps\n",
    "    meta_dict['prediction_task'] = prediction_task\n",
    "    meta_dict['predictions_per_second'] = pps\n",
    "    meta_dict['model_type'] = 'Gretel'\n",
    "    meta_dict.update({'test_dates':str(test_dates),\n",
    "                      'selection_start':selection_start,\n",
    "                      'selection_end':selection_end,\n",
    "                      'selection_step':selection_step,\n",
    "                      'n_test_paths':len(test_paths)})\n",
    "    with open(directory+path_format+'/metadata_'+prediction_task+str(n_steps)+'.json', 'w') as json_file:\n",
    "        json.dump(meta_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e22b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pickle\n",
    "# save model as pickle object\n",
    "fileObj = open('../../models/gretel_prediction_models/trained_models/'+meta_dict['network_name']+filter'.obj', 'wb')\n",
    "pickle.dump(model, fileObj)\n",
    "fileObj.close()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
