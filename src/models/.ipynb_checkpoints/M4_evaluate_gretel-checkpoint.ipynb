{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d6c13d-a271-4d0b-97c7-b8cf9f61d0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geopandas has version 0.13.2\n",
      "Movingpandas has version 0.17.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <script charset=\"utf-8\">\n",
       "    // Load via requireJS if available (jupyter notebook environment)\n",
       "    try {\n",
       "    require.config({\n",
       "    paths: {\n",
       "    d3: \"https://d3js.org/d3.v5.min.js\".replace(\".js\", \"\")\n",
       "    }\n",
       "    });\n",
       "    console.log(\"OKAY: requireJS was detected\");\n",
       "    }\n",
       "    catch(err){\n",
       "    console.log(err);\n",
       "    console.log(\"ERROR: NO requireJS was detected\");\n",
       "    };\n",
       "    require(['d3'], function(d3){\n",
       "    console.log(\"OKAY: d3js was detected\");\n",
       "    });\n",
       "    </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import movingpandas as mpd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "from ast import literal_eval\n",
    "import networkx as nx\n",
    "import folium\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "import sys\n",
    "import json\n",
    "import neptune\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Geopandas has version {}\".format(gpd.__version__))\n",
    "print(\"Movingpandas has version {}\".format(mpd.__version__))\n",
    "\n",
    "# add paths for modules\n",
    "sys.path.append('../visualization')\n",
    "sys.path.append('../features')\n",
    "# import modules\n",
    "import visualize\n",
    "import geometry_utils\n",
    "from maritime_traffic_network import MaritimeTrafficNetwork\n",
    "import prediction_model_evaluation_metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54dee2ea-375d-42a6-ad1c-e9a191d0a027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'network_name': '202204_waypoints_DP10_HDBSCAN13_tromso_full_UTM',\n",
       " 'n_points': 796177,\n",
       " 'n_nodes': 541,\n",
       " 'n_edges': 2139,\n",
       " 'training_dates': \"['202205']\",\n",
       " 'n_training_paths': 1433,\n",
       " 'node_features': \"['n_members']\",\n",
       " 'egde_features': \"['length', 'weight', 'direction']\",\n",
       " 'path_format': 'node2node',\n",
       " 'lr': 0.001,\n",
       " 'loss': 'target_only',\n",
       " 'n_epochs': 20,\n",
       " 'target_prediction': 'next',\n",
       " 'model_type': 'Gretel',\n",
       " 'test_dates': \"['202206']\",\n",
       " 'selection_start': 0,\n",
       " 'selection_end': 1521,\n",
       " 'selection_step': 2,\n",
       " 'n_test_paths': 761,\n",
       " 'n_walks': 100}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path to directory of model\n",
    "location = 'tromso'\n",
    "path_format = 'node2node'\n",
    "directory = '../../models/gretel_prediction_models/'+location+'_small/'+path_format+'/'\n",
    "# load metadata from file\n",
    "with open(directory+'/metadata.json', 'r') as json_file:\n",
    "    meta_dict = json.load(json_file)\n",
    "meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a201cc7-52b1-4544-8e5b-9966c1652c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for prediction\n",
    "prediction_task = 'path'\n",
    "eval_mode = 'path'\n",
    "n_start_nodes=1\n",
    "network_name = meta_dict['network_name']\n",
    "test_dates = literal_eval(meta_dict['test_dates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df22f315-d148-42ac-be72-273e1def6541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Data': '../../data/processed/202204_points_tromso_cleaned_meta_full_dualSplit_2.parquet',\n",
       " 'DP_tolerance': 10,\n",
       " 'clustering_method': 'HDBSCAN',\n",
       " 'clustering_metric': 'mahalanobis',\n",
       " 'clustering_min_samples': 13,\n",
       " 'clustering_min_cluster_size': 13,\n",
       " 'clustering_eps': 0,\n",
       " 'clustering_metric_V': array([[1.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 1.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.01, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.01, 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  , 1.  ]]),\n",
       " 'graph_generation_max_distance': 20,\n",
       " 'graph_generation_max_angle': 45}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load maritime traffic network\n",
    "network_path = '../../models/networks/best_networks/' + network_name + '.obj'\n",
    "fileObj = open(network_path, 'rb')\n",
    "network = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "network.hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b89a381-0ada-466a-b712-be88427f5271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data for prediction model\n",
    "for i in range(0, len(test_dates)):\n",
    "    test_date = test_dates[i]\n",
    "    # Load path data\n",
    "    filename = network_name+'_'+test_date+'_paths.csv'\n",
    "    test_data = pd.read_csv('../../data/paths/'+filename)\n",
    "    test_data['path'] = test_data['path'].apply(literal_eval)\n",
    "    test_data = gpd.GeoDataFrame(test_data, geometry=gpd.GeoSeries.from_wkt(test_data['geometry']), crs=network.crs)\n",
    "    test_data = test_data[test_data['message']=='success']\n",
    "\n",
    "    # Load respective trajectories for evaluation\n",
    "    traj_file = test_date+'_points_'+location+'_cleaned_meta_full_dualSplit_2'\n",
    "    filename = '../../data/processed/' + traj_file + '.parquet'\n",
    "    traj_gdf = gpd.read_parquet(filename)\n",
    "    traj_gdf.to_crs(network.crs, inplace=True)  # Transformation\n",
    "    \n",
    "    if i==0:\n",
    "        all_test_data = test_data\n",
    "        all_traj_gdf = traj_gdf\n",
    "    else:\n",
    "        all_test_data = pd.concat([all_test_data, test_data])\n",
    "        all_traj_gdf = pd.concat([all_traj_gdf, traj_gdf])\n",
    "        \n",
    "test_trajectories = mpd.TrajectoryCollection(all_traj_gdf, traj_id_col='mmsi', obj_id_col='mmsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cfd7d26-a467-4287-ae32-e25b9094ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load predictions from file\n",
    "predictions = pd.read_csv(directory+'predictions.csv')\n",
    "predictions['ground_truth'] = predictions['ground_truth'].apply(literal_eval)\n",
    "predictions['prediction'] = predictions['prediction'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "239c7614-8ba9-40c9-af26-0090c8927259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all predictions are valid\n",
    "for index, row in predictions.iterrows():\n",
    "    if geometry_utils.is_valid_path(network.G, row['ground_truth']) == False:\n",
    "        print(row['mmsi'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d507703e-9aa1-4025-9bf9-b1d4cd4fba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/jandrik91/RoutePredictions/e/ROUT-72\n",
      "Evaluating 760 samples for path prediction task\n",
      "Progress: 10%..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    project=\"jandrik91/RoutePredictions\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxYmQzMjgwZS1jZGYwLTQ2YjktYWNjOS02MjBlZWEzNzUzNDcifQ==\",\n",
    ")  # your credentials\n",
    "\n",
    "# evaluate\n",
    "evaluation_results, fig = metrics.evaluate_given_predictions(prediction_task, predictions, test_trajectories, \n",
    "                                                             network, n_start_nodes=n_start_nodes, eval_mode=eval_mode)\n",
    "\n",
    "nan_mask = evaluation_results.isna().any(axis=1)\n",
    "failure_rate = nan_mask.sum() / len(evaluation_results)\n",
    "mean_abs_err = np.mean(evaluation_results[~nan_mask][\"SSPD\"])\n",
    "median_abs_err = np.median(evaluation_results[~nan_mask][\"SSPD\"])\n",
    "choice_accuracy = np.mean(evaluation_results[~nan_mask][\"choice_accuracy\"])\n",
    "\n",
    "# save experiment\n",
    "run[\"network_name\"] = network_name\n",
    "run[\"n_points\"]=len(network.gdf)\n",
    "run[\"n_nodes\"]=network.G.number_of_nodes()\n",
    "run[\"n_edges\"]=network.G.number_of_edges()\n",
    "\n",
    "params = network.hyperparameters\n",
    "params['clustering_metric_V_coord'] = params['clustering_metric_V'][0][0]\n",
    "params['clustering_metric_V_cog'] = params['clustering_metric_V'][2][2]\n",
    "params['clustering_metric_V_speed'] = params['clustering_metric_V'][4][4]\n",
    "run[\"network_parameters\"] = params\n",
    "\n",
    "run[\"training_data\"] = {'training_dates':meta_dict['training_dates'],\n",
    "                        'n_training_paths':meta_dict['n_training_paths']}\n",
    "\n",
    "run[\"test_data\"] = {'test_dates':str(test_dates),\n",
    "                    'selection_start':meta_dict['selection_start'],\n",
    "                    'selection_end':meta_dict['selection_end'],\n",
    "                    'selection_step':meta_dict['selection_step'],\n",
    "                    'n_test_paths':meta_dict['n_test_paths']}\n",
    "\n",
    "run[\"prediction_task\"] = prediction_task\n",
    "run[\"eval_mode\"] = eval_mode\n",
    "run[\"model_type\"] = meta_dict['model_type']\n",
    "run[\"n_start_nodes\"] = n_start_nodes\n",
    "\n",
    "run['node_features'] = meta_dict['node_features']\n",
    "run['egde_features'] = meta_dict['egde_features']\n",
    "run['path_format'] = meta_dict['path_format']\n",
    "run['lr'] = meta_dict['lr']\n",
    "run['loss'] = meta_dict['loss']\n",
    "run['n_epochs'] = meta_dict['n_epochs']\n",
    "run['MOGen_n_walks'] = meta_dict['n_walks']\n",
    "run['target_prediction'] = meta_dict['target_prediction']\n",
    "\n",
    "run[\"plot\"].upload(fig)\n",
    "run[\"failure_rate\"] = failure_rate\n",
    "run[\"mean_abs_err\"] = mean_abs_err\n",
    "run[\"median_abs_err\"] = median_abs_err\n",
    "run[\"choice_accuracy\"] = choice_accuracy\n",
    "\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dfa6f7-5f86-46cc-8bbd-7915e2312218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
