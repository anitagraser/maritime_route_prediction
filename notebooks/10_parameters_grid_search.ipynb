{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77403721-0f74-4781-8796-7fdcedfc9d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geopandas has version 0.13.2\n",
      "Movingpandas has version 0.17.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import movingpandas as mpd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "import time\n",
    "from scipy.sparse import coo_matrix\n",
    "from shapely.geometry import Point, LineString, MultiLineString\n",
    "from shapely import ops\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import neptune\n",
    "import folium\n",
    "import pickle\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Geopandas has version {}\".format(gpd.__version__))\n",
    "print(\"Movingpandas has version {}\".format(mpd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47dfe936-563b-42f5-8210-00bdf6c16e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add paths for modules\n",
    "sys.path.append('../src/models')\n",
    "sys.path.append('../src/visualization')\n",
    "sys.path.append('../src/features')\n",
    "# import modules\n",
    "import visualize\n",
    "import geometry_utils\n",
    "from maritime_traffic_network import MaritimeTrafficNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2fa99a-a277-40f3-bc38-25f03f9e53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for network creation\n",
    "# read data from file\n",
    "datasize = 'full'\n",
    "orig_filename = '../data/processed/202204_points_stavanger_cleaned_meta_'+datasize+'_dualSplit_2.parquet'\n",
    "gdf = gpd.read_parquet(orig_filename)\n",
    "# Transform to desired CRS\n",
    "# 4326 for WGS 84 (global) // 32632 for UTM 32N (Norway)\n",
    "crs = 32632  # Coordinate reference system\n",
    "gdf.to_crs(crs, inplace=True)  # Transformation\n",
    "# initialize maritime traffic network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c293a7-bd98-4c57-8db5-b20b4f721d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load evaluation data\n",
    "eval_file = '202205_points_stavanger_cleaned_meta_full_dualSplit_2'\n",
    "filename = '../data/processed/' + eval_file + '.parquet'\n",
    "test_gdf = gpd.read_parquet(filename)\n",
    "crs = 32632  # Coordinate reference system\n",
    "test_gdf.to_crs(crs, inplace=True)  # Transformation\n",
    "all_test_trajectories = mpd.TrajectoryCollection(test_gdf, traj_id_col='mmsi', obj_id_col='mmsi')\n",
    "\n",
    "# select evaluation data\n",
    "selection_start = 0\n",
    "selection_end = len(all_test_trajectories)\n",
    "selection_step = 20\n",
    "selection = np.arange(selection_start, selection_end, selection_step)\n",
    "n_trajectories = len(selection)\n",
    "mmsis = test_gdf.mmsi.unique()[selection]\n",
    "test_trajectories = all_test_trajectories.filter('mmsi', mmsis.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c3b5eb-5d96-4d72-bcc1-0820042fe60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/jandrik91/Maritime-Traffic-Network/e/MAR-85\n",
      "Number of AIS messages: 5422129\n",
      "Number of trajectories: 14375\n",
      "Coordinate Reference System (CRS): EPSG:32632\n",
      "Calculating significant turning points with Douglas Peucker algorithm (tolerance = 10) ...\n",
      "Number of significant points detected: 399401 (7.37% of AIS messages)\n",
      "Time elapsed: 4.65 minutes\n",
      "Adding course over ground before and after each turn ...\n"
     ]
    }
   ],
   "source": [
    "# make experiments\n",
    "vals_ms = [20, 25, 30, 35, 40]\n",
    "\n",
    "\n",
    "for i in range (0, len(vals_ms)):\n",
    "    run = neptune.init_run(\n",
    "        project=\"jandrik91/Maritime-Traffic-Network\",\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxYmQzMjgwZS1jZGYwLTQ2YjktYWNjOS02MjBlZWEzNzUzNDcifQ==\",\n",
    "    )  # your credentials\n",
    "\n",
    "    network = MaritimeTrafficNetwork(gdf, crs)\n",
    "    network.get_trajectories_info()\n",
    "    \n",
    "    # parameters\n",
    "    tolerance = 10 # DP tolerance parameter 0.0002\n",
    "    method = 'HDBSCAN'      # 'DBSCAN' , 'HDBSCAN', 'OPTICS'\n",
    "    metric = 'mahalanobis'  # 'euclidean', 'mahalanobis', 'haversine'\n",
    "    min_samples = vals_ms[i]\n",
    "    min_cluster_size = vals_ms[i]\n",
    "    eps = 0\n",
    "    V = np.diag([1, 1, 0.01, 0.01, 1e-4])  # mahalanobis distance parameter matrix V = np.diag([1, 1, 0.01, 0.01, 1e-5])  seems to be good\n",
    "    max_distance = 10\n",
    "    max_angle = 45\n",
    "    merge_stops = True\n",
    "    merge_stops_speed = 2\n",
    "    pruning = 1\n",
    "    model = '202204_waypoints_DP' + str(tolerance) + '_' + method + str(min_samples) +'_stavanger_'+datasize+'_UTM'\n",
    "    # save hyperparameters\n",
    "    params = {\n",
    "        'Data':orig_filename,\n",
    "        'DP_tolerance':tolerance,\n",
    "        'clustering_method':method,\n",
    "        'clustering_metric':metric,\n",
    "        'clustering_min_samples':min_samples,\n",
    "        'clustering_min_cluster_size':min_cluster_size,\n",
    "        'clustering_eps':eps,\n",
    "        'clustering_metric_V':V,\n",
    "        'graph_generation_max_distance':max_distance,\n",
    "        'graph_generation_max_angle':max_angle\n",
    "    }\n",
    "    network.set_hyperparameters(params)\n",
    "    \n",
    "    # calculate significant turning points using Douglas Peucker algorithm\n",
    "    network.calc_significant_points_DP(tolerance)\n",
    "    \n",
    "    # compute waypoints\n",
    "    network.calc_waypoints_clustering(method=method, min_samples=min_samples, min_cluster_size=min_cluster_size,\n",
    "                                      eps=eps, metric=metric, V=V)\n",
    "    # make graph from waypoints\n",
    "    network.make_graph_from_waypoints(max_distance=max_distance, max_angle=max_angle)\n",
    "    \n",
    "    # merge stop points\n",
    "    if merge_stops:\n",
    "        network.merge_stop_points(max_speed=merge_stops_speed)\n",
    "    \n",
    "    # prune graph\n",
    "    network.prune_graph(pruning)\n",
    "\n",
    "    # evaluate\n",
    "    all_paths, all_evaluation_results, summary, fig = network.evaluate_graph(test_trajectories)\n",
    "\n",
    "    # save experiment\n",
    "    run[\"model\"]=model\n",
    "    run[\"n_points\"]=len(network.gdf)\n",
    "    run[\"n_nodes\"]=network.G_pruned.number_of_nodes()\n",
    "    run[\"n_edges\"]=network.G_pruned.number_of_edges()\n",
    "    run[\"n_isolated\"]=nx.number_of_isolates(network.G_pruned)\n",
    "    run[\"merge_stops\"] = merge_stops\n",
    "    run[\"merge_stops_speed\"] = merge_stops_speed\n",
    "    run[\"pruning\"] = pruning\n",
    "    \n",
    "    params = network.hyperparameters\n",
    "    params['clustering_metric_V_coord'] = params['clustering_metric_V'][0][0]\n",
    "    params['clustering_metric_V_cog'] = params['clustering_metric_V'][2][2]\n",
    "    params['clustering_metric_V_speed'] = params['clustering_metric_V'][4][4]\n",
    "    run[\"parameters\"] = params\n",
    "    \n",
    "    run[\"test_data\"] = {'eval_file':eval_file,\n",
    "                        'selection_start':selection_start,\n",
    "                        'selection_end':selection_end,\n",
    "                        'selection_step':selection_step,\n",
    "                        'n_trajectories':n_trajectories}\n",
    "    \n",
    "    run[\"plot\"].upload(fig)\n",
    "    run[\"summary\"] = summary\n",
    "    \n",
    "    run.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
