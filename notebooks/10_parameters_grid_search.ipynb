{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77403721-0f74-4781-8796-7fdcedfc9d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geopandas has version 0.13.2\n",
      "Movingpandas has version 0.17.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import movingpandas as mpd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "import time\n",
    "from scipy.sparse import coo_matrix\n",
    "from shapely.geometry import Point, LineString, MultiLineString\n",
    "from shapely import ops\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import neptune\n",
    "import folium\n",
    "import pickle\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Geopandas has version {}\".format(gpd.__version__))\n",
    "print(\"Movingpandas has version {}\".format(mpd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47dfe936-563b-42f5-8210-00bdf6c16e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add paths for modules\n",
    "sys.path.append('../src/models')\n",
    "sys.path.append('../src/visualization')\n",
    "sys.path.append('../src/features')\n",
    "# import modules\n",
    "import visualize\n",
    "import geometry_utils\n",
    "from maritime_traffic_network import MaritimeTrafficNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2fa99a-a277-40f3-bc38-25f03f9e53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for network creation\n",
    "# read data from file\n",
    "datasize = 'full'\n",
    "location = 'tromso'\n",
    "data_date = '202204'\n",
    "eval_date = '202205'\n",
    "\n",
    "orig_filename = '../data/processed/'+data_date+'_points_'+location+'_cleaned_meta_'+datasize+'_dualSplit_2.parquet'\n",
    "gdf = gpd.read_parquet(orig_filename)\n",
    "# Transform to desired CRS\n",
    "# 4326 for WGS 84 (global) // 32632 for UTM 32N (Norway)\n",
    "crs = 32632  # Coordinate reference system\n",
    "gdf.to_crs(crs, inplace=True)  # Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c293a7-bd98-4c57-8db5-b20b4f721d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load evaluation data\n",
    "eval_file = eval_date+'_points_'+location+'_cleaned_meta_full_dualSplit_2'\n",
    "filename = '../data/processed/' + eval_file + '.parquet'\n",
    "test_gdf = gpd.read_parquet(filename)\n",
    "crs = 32632  # Coordinate reference system\n",
    "test_gdf.to_crs(crs, inplace=True)  # Transformation\n",
    "all_test_trajectories = mpd.TrajectoryCollection(test_gdf, traj_id_col='mmsi', obj_id_col='mmsi')\n",
    "\n",
    "# select evaluation data\n",
    "selection_start = 1\n",
    "selection_end = len(all_test_trajectories)\n",
    "selection_step = 3\n",
    "selection = np.arange(selection_start, selection_end, selection_step)\n",
    "n_trajectories = len(selection)\n",
    "mmsis = test_gdf.mmsi.unique()[selection]\n",
    "test_trajectories = all_test_trajectories.filter('mmsi', mmsis.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a5377a-4fe0-40d2-9348-47a609380534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load significant points\n",
    "#sp_gdf = gpd.read_parquet('../data/processed/202204_significant_points_DP10_stavanger_full_UTM.parquet')\n",
    "#sp_gdf.to_crs(crs, inplace=True)  # Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c3b5eb-5d96-4d72-bcc1-0820042fe60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/jandrik91/Maritime-Traffic-Network/e/MAR-330\n",
      "Number of AIS messages: 796177\n",
      "Number of trajectories: 2119\n",
      "Coordinate Reference System (CRS): EPSG:32632\n",
      "Calculating significant turning points with Douglas Peucker algorithm (tolerance = 10) ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m network\u001b[38;5;241m.\u001b[39mset_hyperparameters(params)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# calculate significant turning points using Douglas Peucker algorithm\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_significant_points_DP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#network.init_precomputed_significant_points(sp_gdf)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# compute waypoints\u001b[39;00m\n\u001b[1;32m     53\u001b[0m network\u001b[38;5;241m.\u001b[39mcalc_waypoints_clustering(method\u001b[38;5;241m=\u001b[39mmethod, min_samples\u001b[38;5;241m=\u001b[39mmin_samples, min_cluster_size\u001b[38;5;241m=\u001b[39mmin_cluster_size,\n\u001b[1;32m     54\u001b[0m                                   eps\u001b[38;5;241m=\u001b[39meps, metric\u001b[38;5;241m=\u001b[39mmetric, V\u001b[38;5;241m=\u001b[39mV)\n",
      "File \u001b[0;32m~/maritime_route_prediction/notebooks/../src/models/maritime_traffic_network.py:82\u001b[0m, in \u001b[0;36mMaritimeTrafficNetwork.calc_significant_points_DP\u001b[0;34m(self, tolerance)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalculating significant turning points with Douglas Peucker algorithm (tolerance = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtolerance\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     81\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# start timer\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignificant_points_trajectory \u001b[38;5;241m=\u001b[39m \u001b[43mmpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDouglasPeuckerGeneralizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrajectories\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneralize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m n_points, n_DP_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgdf), \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignificant_points_trajectory\u001b[38;5;241m.\u001b[39mto_point_gdf())\n\u001b[1;32m     84\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# end timer\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_geo/lib/python3.11/site-packages/movingpandas/trajectory_generalizer.py:45\u001b[0m, in \u001b[0;36mTrajectoryGeneralizer.generalize\u001b[0;34m(self, tolerance)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generalize_traj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraj, tolerance)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraj, TrajectoryCollection):\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generalize_traj_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_geo/lib/python3.11/site-packages/movingpandas/trajectory_generalizer.py:52\u001b[0m, in \u001b[0;36mTrajectoryGeneralizer._generalize_traj_collection\u001b[0;34m(self, tolerance)\u001b[0m\n\u001b[1;32m     50\u001b[0m generalized \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m traj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraj:\n\u001b[0;32m---> 52\u001b[0m     generalized\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generalize_traj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     53\u001b[0m result \u001b[38;5;241m=\u001b[39m copy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraj)\n\u001b[1;32m     54\u001b[0m result\u001b[38;5;241m.\u001b[39mtrajectories \u001b[38;5;241m=\u001b[39m generalized\n",
      "File \u001b[0;32m~/miniforge3/envs/env_geo/lib/python3.11/site-packages/movingpandas/trajectory_generalizer.py:197\u001b[0m, in \u001b[0;36mDouglasPeuckerGeneralizer._generalize_traj\u001b[0;34m(self, traj, tolerance)\u001b[0m\n\u001b[1;32m    192\u001b[0m keep_rows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    193\u001b[0m simplified \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    194\u001b[0m     traj\u001b[38;5;241m.\u001b[39mto_linestring()\u001b[38;5;241m.\u001b[39msimplify(tolerance, preserve_topology\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mcoords\n\u001b[1;32m    195\u001b[0m )\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (_, row) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(traj\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miterrows()):\n\u001b[1;32m    198\u001b[0m     current_pt \u001b[38;5;241m=\u001b[39m row[traj\u001b[38;5;241m.\u001b[39mget_geom_col()]\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m current_pt\u001b[38;5;241m.\u001b[39mcoords[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m simplified:\n",
      "File \u001b[0;32m~/miniforge3/envs/env_geo/lib/python3.11/site-packages/pandas/core/frame.py:1453\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1451\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m-> 1453\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1454\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[1;32m   1455\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_geo/lib/python3.11/site-packages/geopandas/geodataframe.py:1640\u001b[0m, in \u001b[0;36mGeoDataFrame._constructor_sliced.<locals>._geodataframe_constructor_sliced\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_geodataframe_constructor_sliced\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;124;03m    A specialized (Geo)Series constructor which can fall back to a\u001b[39;00m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;124;03m    Series if a certain operation does not produce geometries:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;124;03m      checking the identity of the index)\u001b[39;00m\n\u001b[1;32m   1639\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1640\u001b[0m     srs \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1641\u001b[0m     is_row_proxy \u001b[38;5;241m=\u001b[39m srs\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_geometry_type(srs) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_row_proxy:\n",
      "File \u001b[0;32m~/miniforge3/envs/env_geo/lib/python3.11/site-packages/pandas/core/series.py:502\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    500\u001b[0m         data \u001b[38;5;241m=\u001b[39m [data]\n\u001b[1;32m    501\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(data))\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mis_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    503\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(data, index)\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# create/copy the manager\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# make experiments\n",
    "vals_ms = [35, 30, 25, 20, 18, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6]\n",
    "vals_DP = []\n",
    "vals_v34 = []\n",
    "vals_v5 = []\n",
    "vals_max_dist = []\n",
    "vals_max_angle = []\n",
    "\n",
    "\n",
    "for i in range (0, len(vals_ms)):\n",
    "    run = neptune.init_run(\n",
    "        project=\"jandrik91/Maritime-Traffic-Network\",\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxYmQzMjgwZS1jZGYwLTQ2YjktYWNjOS02MjBlZWEzNzUzNDcifQ==\",\n",
    "    )  # your credentials\n",
    "\n",
    "    network = MaritimeTrafficNetwork(gdf, crs)\n",
    "    network.get_trajectories_info()\n",
    "    \n",
    "    # parameters\n",
    "    tolerance = 10 # DP tolerance parameter 0.0002\n",
    "    method = 'HDBSCAN'      # 'DBSCAN' , 'HDBSCAN', 'OPTICS'\n",
    "    metric = 'mahalanobis'  # 'euclidean', 'mahalanobis', 'haversine'\n",
    "    min_samples = vals_ms[i]\n",
    "    min_cluster_size = vals_ms[i]\n",
    "    eps = 0\n",
    "    V = np.diag([1, 1, 0.01, 0.01, 5e-4])  # mahalanobis distance parameter matrix V = np.diag([1, 1, 0.01, 0.01, 5e-4])  seems to be good\n",
    "    max_distance = 10\n",
    "    max_angle = 45\n",
    "    merge_stops = True\n",
    "    merge_stops_speed = 2\n",
    "    pruning = 1\n",
    "    model = data_date+'_waypoints_DP' + str(tolerance) + '_' + method + str(min_samples) +'_'+location+'_'+datasize+'_UTM'\n",
    "    # save hyperparameters\n",
    "    params = {\n",
    "        'Data':orig_filename,\n",
    "        'DP_tolerance':tolerance,\n",
    "        'clustering_method':method,\n",
    "        'clustering_metric':metric,\n",
    "        'clustering_min_samples':min_samples,\n",
    "        'clustering_min_cluster_size':min_cluster_size,\n",
    "        'clustering_eps':eps,\n",
    "        'clustering_metric_V':V,\n",
    "        'graph_generation_max_distance':max_distance,\n",
    "        'graph_generation_max_angle':max_angle\n",
    "    }\n",
    "    network.set_hyperparameters(params)\n",
    "    \n",
    "    # calculate significant turning points using Douglas Peucker algorithm\n",
    "    network.calc_significant_points_DP(tolerance)\n",
    "    #network.init_precomputed_significant_points(sp_gdf)\n",
    "    \n",
    "    # compute waypoints\n",
    "    network.calc_waypoints_clustering(method=method, min_samples=min_samples, min_cluster_size=min_cluster_size,\n",
    "                                      eps=eps, metric=metric, V=V)\n",
    "    # make graph from waypoints\n",
    "    network.make_graph_from_waypoints(max_distance=max_distance, max_angle=max_angle)\n",
    "    \n",
    "    # merge stop points\n",
    "    if merge_stops:\n",
    "        network.merge_stop_points(max_speed=merge_stops_speed)\n",
    "    \n",
    "    # prune graph\n",
    "    network.prune_graph(pruning)\n",
    "\n",
    "    # evaluate\n",
    "    all_paths, all_evaluation_results, summary, fig = network.evaluate_graph(test_trajectories)\n",
    "\n",
    "    # save experiment\n",
    "    run[\"model\"]=model\n",
    "    run[\"algorithm\"]='V5.0'\n",
    "    run[\"n_points\"]=len(network.gdf)\n",
    "    run[\"n_nodes\"]=network.G_pruned.number_of_nodes()\n",
    "    run[\"n_edges\"]=network.G_pruned.number_of_edges()\n",
    "    run[\"n_isolated\"]=nx.number_of_isolates(network.G_pruned)\n",
    "    run[\"merge_stops\"] = merge_stops\n",
    "    run[\"merge_stops_speed\"] = merge_stops_speed\n",
    "    run[\"pruning\"] = pruning\n",
    "    \n",
    "    params = network.hyperparameters\n",
    "    params['clustering_metric_V_coord'] = params['clustering_metric_V'][0][0]\n",
    "    params['clustering_metric_V_cog'] = params['clustering_metric_V'][2][2]\n",
    "    params['clustering_metric_V_speed'] = params['clustering_metric_V'][4][4]\n",
    "    run[\"parameters\"] = params\n",
    "    \n",
    "    run[\"test_data\"] = {'eval_file':eval_file,\n",
    "                        'selection_start':selection_start,\n",
    "                        'selection_end':selection_end,\n",
    "                        'selection_step':selection_step,\n",
    "                        'n_trajectories':n_trajectories}\n",
    "    \n",
    "    run[\"plot\"].upload(fig)\n",
    "    run[\"summary\"] = summary\n",
    "    \n",
    "    run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea502aa0-df65-4f8b-b672-de2c528d4d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save network as pickle object\n",
    "#fileObj = open('../data/interim/202204_waypoints_DP10_HDBSCAN15_stavanger_full_UTM.obj', 'wb')\n",
    "#pickle.dump(network, fileObj)\n",
    "#fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e05175-05f5-43e8-89ae-763f8d99146d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
