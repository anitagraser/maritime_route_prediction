{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb7a4f-98fc-4595-b3f0-ded9cc8969c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook allows us to perform a grid search over prediction model parameters\n",
    "Supported models: 'Random', 'Markov', 'MOGen', 'Dijkstra'. GRETEL does not run in this environment\n",
    "- Load a maritime traffic network, training and test data from file\n",
    "- Specify the model to be trained and the hyperparameters for a grid search\n",
    "The specified models will be trained on the training data and evaluated on the test data. Experiment results will be logged with neptune.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b4270f-95fc-4bed-8d30-6580ba3dd190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathpy as pp\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import movingpandas as mpd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "from ast import literal_eval\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "import sys\n",
    "import neptune\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115dced0-b6e5-41d9-b35c-a69ab7be3f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add paths for modules\n",
    "sys.path.append('../src/models')\n",
    "sys.path.append('../src/features')\n",
    "sys.path.append('../src/visualization')\n",
    "sys.path.append('../src/datawrangling')\n",
    "\n",
    "import dataloader_paths, dataloader_geo\n",
    "from maritime_traffic_network import MaritimeTrafficNetwork\n",
    "from MOGen_path_prediction import MOGenPathPrediction\n",
    "from dijkstra_path_prediction import DijkstraPathPrediction\n",
    "from random_path_prediction import RandomWalkPathPrediction\n",
    "import prediction_model_evaluation_metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc538d-f911-4dbc-9823-6264406ba753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify maritime traffic network\n",
    "datasize = 'full'\n",
    "location = 'tromso'\n",
    "network_date = '202204'\n",
    "DP_tol = 10\n",
    "min_samples = 13\n",
    "\n",
    "# Specify training and test data\n",
    "train_dates = ['202204', '202205', '202207']\n",
    "test_dates = ['202206']\n",
    "train_filter = 'Last'  # Ship category filter: None, 'Last', 'Passasjer', 'Tank', 'Fisk', 'Auxiliary', 'Unknown'\n",
    "test_filter = 'Last'  # Ship category filter: None, 'Last', 'Passasjer', 'Tank', 'Fisk', 'Auxiliary', 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad0701-014f-4b8c-86c7-dade64f4ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a maritime traffic network from pickle\n",
    "network_name = network_date+'_waypoints_DP'+str(DP_tol)+'_HDBSCAN'+str(min_samples)+'_'+location+'_'+datasize+'_UTM'\n",
    "network_path = '../models/networks/best_networks/' + network_name + '.obj'\n",
    "fileObj = open(network_path, 'rb')\n",
    "network = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "network.hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f42aa-4055-452e-b938-8595ca56b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data from file\n",
    "path_prefix = '../data/paths/'\n",
    "training_paths = dataloader_paths.load_path_training_data(path_prefix, network_name, train_dates, filter=train_filter, data_version='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb7fe8d-2cb5-4398-a373-6b13f86154ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data from file\n",
    "traj_path_prefix = '../data/processed/'\n",
    "all_test_paths = dataloader_paths.load_path_test_data(path_prefix, network_name, test_dates, \n",
    "                                                      0, -1, 1, filter=test_filter, data_version='')\n",
    "test_trajectories = dataloader_geo.load_trajectories(traj_path_prefix, location, network.crs, test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cba528-bfc4-4bc2-a9a4-c272f7d0645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify parameters for grid search\n",
    "prediction_task = 'next_nodes'  # 'path' for subtask 1 and 'next_nodes' for subtask 2\n",
    "eval_mode = 'path'              # evaluate the prediction against 'path' or 'trajectory'\n",
    "model_type = 'MOGen'            # supported models: 'Random', 'Markov', 'MOGen', 'Dijkstra'. GRETEL does not run in this environment\n",
    "vals_n_steps = [10]             # prediction horizon\n",
    "vals_n_walks = [1000]           # number of random walks\n",
    "vals_max_order = [4]            # Maximum order of a MOGen model\n",
    "vals_order = [0]                # Force order of a MOGen model (if 0, optimal order is used by the model)\n",
    "MOGen_training_mode = 'partial' # MOGen only: 'partial' (recommended) or 'full' (splits paths into subpaths and trains the model on these)\n",
    "vals_n_start_nodes = [1]        # number of observed start nodes\n",
    "weight_vals = ['length', 'inverse_passages', 'inverse_density']  # edge weights for Dijkstra model\n",
    "\n",
    "# sample test paths\n",
    "selection_start = 0\n",
    "selection_end = -1\n",
    "selection_step = 2\n",
    "\n",
    "# run experiments\n",
    "for i in range (0, len(vals_n_walks)):\n",
    "    run = neptune.init_run(\n",
    "        project=\"project\",\n",
    "        api_token=\"token\",\n",
    "    )  # your credentials\n",
    "\n",
    "    # training parameters (specify manually or loop through parameters specified above)\n",
    "    n_walks = vals_n_walks[i]\n",
    "    MOGen_max_order = vals_max_order[i]\n",
    "    n_start_nodes = vals_n_start_nodes[i]\n",
    "    n_steps = vals_n_steps[i]\n",
    "    order = vals_order[i]\n",
    "    weight = weight_vals[i]\n",
    "\n",
    "    # prepare test data\n",
    "    if prediction_task == 'next_nodes':\n",
    "        # split test paths in subpaths and sample from the subpaths\n",
    "        sub_paths = dataloader_paths.split_path_data(all_test_paths, n_steps+1)\n",
    "        test_paths = dataloader_paths.sample_path_data(sub_paths, selection_start, selection_end, selection_step)\n",
    "    else:\n",
    "        # sample from original test paths\n",
    "        test_paths = dataloader_paths.sample_path_data(all_test_paths, selection_start, selection_end, selection_step)\n",
    "    n_test_paths=len(test_paths)\n",
    "        \n",
    "    # train and predict\n",
    "    if model_type == 'Dijkstra':\n",
    "        model = DijkstraPathPrediction()\n",
    "        model.train(network.G_pruned, training_paths)\n",
    "        predictions = model.predict(test_paths, n_start_nodes=n_start_nodes, weight=weight)\n",
    "    if model_type == 'MOGen':\n",
    "        model = MOGenPathPrediction()\n",
    "        model.train(training_paths, max_order=MOGen_max_order, model_selection=True, training_mode=MOGen_training_mode)\n",
    "        predictions = model.predict(prediction_task, test_paths, network.G, \n",
    "                                    n_start_nodes=n_start_nodes, n_steps=n_steps, \n",
    "                                    n_predictions=1, n_walks=n_walks, order=order)\n",
    "    if model_type == 'Random':\n",
    "        model = RandomWalkPathPrediction()\n",
    "        model.train(network.G_pruned, training_paths)\n",
    "        predictions = model.predict(test_paths, n_start_nodes, n_steps, \n",
    "                                    1, n_walks, method='random')\n",
    "    if model_type == 'Markov':\n",
    "        model = RandomWalkPathPrediction()\n",
    "        model.train(network.G_pruned, training_paths)\n",
    "        predictions = model.predict(test_paths, n_start_nodes, n_steps, \n",
    "                                    1, n_walks, method='weighted')\n",
    "        \n",
    "    # evaluate\n",
    "    evaluation_results, fig = metrics.evaluate_given_predictions(prediction_task, predictions, test_trajectories, \n",
    "                                                                 network, n_start_nodes=n_start_nodes, n_steps=n_steps, eval_mode=eval_mode)\n",
    "    nan_mask = evaluation_results.isna().any(axis=1)\n",
    "    failure_rate = nan_mask.sum() / len(evaluation_results)\n",
    "    mean_abs_err = np.mean(evaluation_results[~nan_mask][\"SSPD\"])\n",
    "    median_abs_err = np.median(evaluation_results[~nan_mask][\"SSPD\"])\n",
    "    choice_accuracy = np.mean(evaluation_results[~nan_mask][\"choice_accuracy\"])\n",
    "\n",
    "    # save experiment\n",
    "    run[\"network_name\"] = network_name\n",
    "    run[\"n_points\"]=len(network.gdf)\n",
    "    run[\"n_nodes\"]=network.G.number_of_nodes()\n",
    "    run[\"n_edges\"]=network.G.number_of_edges()\n",
    "    \n",
    "    params = network.hyperparameters\n",
    "    params['clustering_metric_V_coord'] = params['clustering_metric_V'][0][0]\n",
    "    params['clustering_metric_V_cog'] = params['clustering_metric_V'][2][2]\n",
    "    params['clustering_metric_V_speed'] = params['clustering_metric_V'][4][4]\n",
    "    run[\"network_parameters\"] = params\n",
    "    \n",
    "    run[\"training_data\"] = {'training_dates':str(train_dates),\n",
    "                            'n_training_paths':len(training_paths)}\n",
    "    \n",
    "    run[\"test_data\"] = {'test_dates':str(test_dates),\n",
    "                        'selection_start':selection_start,\n",
    "                        'selection_end':selection_end,\n",
    "                        'selection_step':selection_step,\n",
    "                        'n_test_paths':n_test_paths}\n",
    "    \n",
    "    run[\"prediction_task\"] = prediction_task\n",
    "    run[\"eval_mode\"] = eval_mode\n",
    "    run[\"model_type\"] = model_type\n",
    "    run[\"MOGen_n_walks\"] = n_walks\n",
    "    run[\"MOGen_max_order\"] = MOGen_max_order\n",
    "    if model_type == 'MOGen':\n",
    "        run[\"MOGen_optimal_order\"] = model.order\n",
    "    if model_type == 'Dijkstra':\n",
    "        run[\"weight\"] = weight\n",
    "    run[\"MOGen_training_mode\"] = MOGen_training_mode\n",
    "    run[\"n_start_nodes\"] = n_start_nodes\n",
    "    run[\"n_steps\"] = n_steps\n",
    "    \n",
    "    run[\"plot\"].upload(fig)\n",
    "    run[\"failure_rate\"] = failure_rate\n",
    "    run[\"mean_abs_err\"] = mean_abs_err\n",
    "    run[\"median_abs_err\"] = median_abs_err\n",
    "    run[\"choice_accuracy\"] = choice_accuracy\n",
    "    run[\"train_filter\"] = train_filter\n",
    "    run[\"test_filter\"] = test_filter\n",
    "    \n",
    "    run.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
