{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7845c4c4-9e35-4d0b-8d57-1169de706903",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook compares the results of different route prediction models in terms of evaluation metrics\n",
    "- experiment data is loaded from file (neptune export)\n",
    "- plots for subtasks 1 and 2 are generated\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f61ef-4e77-4033-84cc-5535e367f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import movingpandas as mpd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "import time\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Geopandas has version {}\".format(gpd.__version__))\n",
    "print(\"Movingpandas has version {}\".format(mpd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96052793-56b1-4794-9a75-49b5970a711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read experiment results from file (neptune export)\n",
    "eval_df = pd.read_csv('../reports/RoutePredictions-2.csv')\n",
    "eval_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74c127-f67a-403a-bdc5-9790336962e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print overview of hyperparameters\n",
    "print('Models', sorted(eval_df.Model.unique()))\n",
    "print('Task', sorted(eval_df.Task.unique()))\n",
    "print('n_steps', sorted(eval_df.n_steps.unique()))\n",
    "print('n_start_nodes', sorted(eval_df.n_start_nodes.unique()))\n",
    "print('n_training_paths', sorted(eval_df.n_training_paths.unique()))\n",
    "print('n_test_paths', sorted(eval_df.n_test_paths.unique()))\n",
    "print('node_features', eval_df.node_features.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614032a5-f47e-4f41-9cf5-556d6d31c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plot performance of subtask 2 (next_node prediction task) for all networks\n",
    "# specify networks\n",
    "networks = ['Tromsø', 'Oslo', 'Stavanger']\n",
    "networks_n_paths = [4449, 21058, 36924]\n",
    "\n",
    "# define metrics\n",
    "metric1 = 'mean_abs_err'\n",
    "metric2 = 'choice_accuracy'\n",
    "ylims = [[50, 3000], [100,5000], [100,6000]]\n",
    "\n",
    "# plot for each network\n",
    "for i in range(3):\n",
    "    network = networks[i]\n",
    "    n = networks_n_paths[i]\n",
    "\n",
    "    # sort data\n",
    "    eval_df.sort_values(by='n_steps', inplace=True)\n",
    "\n",
    "    # prepare figure and axes\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))  # Set the figure size\n",
    "    filter = ((eval_df['n_training_paths']==n) & (eval_df['Model'] == 'MOGen'))\n",
    "    x = eval_df[filter]['n_steps'].unique()\n",
    "    \n",
    "    axes[0].set_xlabel('k')\n",
    "    axes[0].set_ylabel('$MD_{SSPD}$')\n",
    "    axes[0].tick_params(axis='y')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_yscale('log')\n",
    "    axes[0].set_ylim(ylims[i])\n",
    "    \n",
    "    axes[1].set_xlabel('k')\n",
    "    axes[1].set_ylabel('$CACC$') \n",
    "    axes[1].tick_params(axis='y')\n",
    "    axes[1].set_xticks(x)\n",
    "\n",
    "    # plot Markov model results\n",
    "    filter = ((eval_df['Model'] == 'Markov') & (eval_df['n_training_paths']==n) & (eval_df['Task']=='next_nodes') & (eval_df['eval_mode']=='path'))\n",
    "    y1 = eval_df[filter][metric1]\n",
    "    y2 = eval_df[filter][metric2]\n",
    "    axes[0].plot(x, y1, label='Markov')\n",
    "    axes[1].plot(x, y2, label='Markov')\n",
    "\n",
    "    # plot MOGen model results\n",
    "    filter = ((eval_df['Model'] == 'MOGen') & (eval_df['n_training_paths']==n) & (eval_df['Task']=='next_nodes') & (eval_df['MOGen_optimal_order']==2) & (eval_df['eval_mode']=='path'))\n",
    "    y1 = eval_df[filter][metric1]\n",
    "    y2 = eval_df[filter][metric2]\n",
    "    axes[0].plot(x, y1, label='MOGen')\n",
    "    axes[1].plot(x, y2, label='MOGen')\n",
    "\n",
    "    # plot GRETEL model results\n",
    "    filter = ((eval_df['Model'] == 'Gretel') & (eval_df['n_training_paths']==n) & (eval_df['Task']=='next_nodes') & (eval_df['loss']=='target_only') & \n",
    "              (eval_df['node_features']==\"['n_members', 'speed', 'cog_before', 'cog_after', 'lat', 'lon']\") & (eval_df['eval_mode']=='path'))\n",
    "    y1 = eval_df[filter][metric1]\n",
    "    y2 = eval_df[filter][metric2]\n",
    "    axes[0].plot(x, y1, label='GRETEL')\n",
    "    axes[1].plot(x, y2, label='GRETEL')\n",
    "    \n",
    "    # add legend\n",
    "    plt.legend()\n",
    "    \n",
    "    # Add title\n",
    "    fig.suptitle(network)\n",
    "    \n",
    "    fig.tight_layout()  # Adjust layout\n",
    "    plt.savefig('subtask2_'+network+'_log.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4bd71e-6dd1-44d6-9b2c-37e27982c8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plot performance of subtask 1 (path prediction task) for all networks\n",
    "# filter data for subtask 1\n",
    "subtask1_df = eval_df[eval_df.Task=='path']\n",
    "\n",
    "# specify networks\n",
    "networks = ['Tromso', 'Oslo', 'Stavanger']\n",
    "networks_n_paths = [4449, 21058, 36924]\n",
    "\n",
    "# define metrics\n",
    "metric1 = 'choice_accuracy'\n",
    "metric2 = 'mean_abs_err'\n",
    "metric3 = 'median_abs_err'\n",
    "\n",
    "# sort data\n",
    "eval_df.sort_values(by='n_training_paths', inplace=True)\n",
    "\n",
    "# prepare figure and axes\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))  # Set the figure size\n",
    "\n",
    "ax[0].set_xlabel('$CACC$')\n",
    "ax[0].set_ylabel('$MD_{SSPD}$')\n",
    "\n",
    "ax[1].set_xlabel('$CACC$')\n",
    "ax[1].set_ylabel('$MedD_{SSPD}$')\n",
    "\n",
    "\n",
    "# plot Dijkstra model results\n",
    "filter = ((eval_df['Model'] == 'Dijkstra') & (eval_df['weight']=='inverse_density') & (eval_df['Task']=='path') & (eval_df['eval_mode']=='path'))\n",
    "x1 = eval_df[filter][metric1]\n",
    "y1 = eval_df[filter][metric2]\n",
    "y11 = eval_df[filter][metric3]\n",
    "scatter = ax[0].scatter(x1, y1, color='blue', marker='o', s=100)\n",
    "scatter = ax[1].scatter(x1, y11, color='blue', marker='o', s=100)\n",
    "# Annotate each point with the ship category name\n",
    "for i, network in enumerate(networks):\n",
    "    ax[0].annotate(network, (x1.iloc[i], y1.iloc[i]), textcoords=\"offset points\", xytext=(5,5), ha='left')\n",
    "    ax[1].annotate(network, (x1.iloc[i], y11.iloc[i]), textcoords=\"offset points\", xytext=(5,5), ha='left')\n",
    "\n",
    "# plot MOGen model results\n",
    "filter = ((eval_df['Model'] == 'MOGen') & (eval_df['Task']=='path') & (eval_df['MOGen_optimal_order']==2) & (eval_df['eval_mode']=='path'))\n",
    "x2 = eval_df[filter][metric1]\n",
    "y2 = eval_df[filter][metric2]\n",
    "y22 = eval_df[filter][metric3]\n",
    "scatter = ax[0].scatter(x2, y2, color='orange', marker='o', s=100)\n",
    "scatter = ax[1].scatter(x2, y22, color='orange', marker='o', s=100)\n",
    "# Annotate each point with the ship category name\n",
    "for i, network in enumerate(networks):\n",
    "    ax[0].annotate(network, (x2.iloc[i], y2.iloc[i]), textcoords=\"offset points\", xytext=(5,5), ha='left')\n",
    "    ax[1].annotate(network, (x2.iloc[i], y22.iloc[i]), textcoords=\"offset points\", xytext=(5,5), ha='left')\n",
    "\n",
    "# plot GRETEL model results\n",
    "filter = ((eval_df['Model'] == 'Gretel') & (eval_df['Task']=='path') & (eval_df['n_test_paths']!=191) & (eval_df['loss']=='target_only') &\n",
    "          (eval_df['node_features']==\"['n_members', 'speed', 'cog_before', 'cog_after', 'lat', 'lon']\") & (eval_df['eval_mode']=='path'))\n",
    "x3 = eval_df[filter][metric1]\n",
    "y3 = eval_df[filter][metric2]\n",
    "y33 = eval_df[filter][metric3]\n",
    "scatter = ax[0].scatter(x3, y3, color='green', marker='o', s=100)\n",
    "scatter = ax[1].scatter(x3, y33, color='green', marker='o', s=100)\n",
    "# Annotate each point with the ship category name\n",
    "for i, network in enumerate(networks):\n",
    "    ax[0].annotate(network, (x3.iloc[i], y3.iloc[i]), textcoords=\"offset points\", xytext=(5,5), ha='left')\n",
    "    ax[1].annotate(network, (x3.iloc[i], y33.iloc[i]), textcoords=\"offset points\", xytext=(5,5), ha='left')\n",
    "\n",
    "# adjust axes limits\n",
    "ax[0].set_ylim(0,800)\n",
    "ax[0].set_xlim(0.3,0.75)\n",
    "ax[1].set_ylim(0,100)\n",
    "ax[1].set_xlim(0.3,0.75)\n",
    "\n",
    "# add legend\n",
    "legend_labels = ['Dijkstra', 'MOGen', 'GRETEL']\n",
    "ax[0].legend(legend_labels, loc='upper left')\n",
    "\n",
    "# Add title\n",
    "fig.suptitle('performance subtask 1')\n",
    "\n",
    "fig.tight_layout()  # Adjust layout\n",
    "plt.savefig('subtask1.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f2d576-b39b-447a-8a88-3027a74fc68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance for subtask 2 to compare evaluation against path or trajectory\n",
    "# specify networks\n",
    "networks = ['Tromsø', 'Oslo', 'Stavanger']\n",
    "networks_n_paths = [4449, 21058, 36924]\n",
    "\n",
    "# define metrics\n",
    "metric1 = 'median_abs_err'\n",
    "\n",
    "# sort data\n",
    "eval_df.sort_values(by='n_steps', inplace=True)\n",
    "\n",
    "# prepare figure and axes\n",
    "fig, ax = plt.subplots(figsize=(5, 4))  # Set the figure size\n",
    "filter = ((eval_df['n_training_paths']==n) & (eval_df['Model'] == 'Markov'))\n",
    "x = np.array([1, 2, 3, 5, 10, 15])\n",
    "\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('$\\Delta MedD_{SSPD}$') \n",
    "ax.tick_params(axis='y')\n",
    "ax.set_xticks(x)\n",
    "\n",
    "# plot for each network\n",
    "for i in range(3):\n",
    "    network = networks[i]\n",
    "    n = networks_n_paths[i]\n",
    "    \n",
    "    # retrieve Markov model results\n",
    "    filter = ((eval_df['Model'] == 'Markov') & (eval_df['n_training_paths']==n) & (eval_df['Task']=='next_nodes') & (eval_df['eval_mode']=='path') & (eval_df['n_steps']<20))\n",
    "    y1_path = np.array(eval_df[filter][metric1])\n",
    "\n",
    "    filter = ((eval_df['Model'] == 'Markov') & (eval_df['n_training_paths']==n) & (eval_df['Task']=='next_nodes') & (eval_df['eval_mode']=='trajectory') & (eval_df['n_steps']<20))\n",
    "    y1_traj = np.array(eval_df[filter][metric1])\n",
    "    \n",
    "    # plot\n",
    "    ax.plot(x, y1_traj-y1_path, label=network)\n",
    "    \n",
    "    \n",
    "# add legend\n",
    "plt.legend()  \n",
    "plt.title('Difference in Median SSPD when evaluating the prediction against ground truth path vs ground truth trajectory')\n",
    "fig.tight_layout()  # Adjust layout\n",
    "plt.savefig('subtask2__pathVStraj.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eaa087-cab7-4f43-bd87-2242386c52aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance for subtask 1 for evaluation against path or trajectory\n",
    "eval_df.sort_values(by='n_training_paths', inplace=True)\n",
    "filter = ((eval_df['Model'] == 'Dijkstra') & (eval_df['weight']=='inverse_density') & (eval_df['Task']=='path'))\n",
    "columns = ['network_name', 'eval_mode', 'median_abs_err', 'mean_abs_err']\n",
    "eval_df[filter][columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da43dcd-b8ca-4b4f-9357-6e88ed635a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
