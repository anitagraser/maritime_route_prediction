{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77403721-0f74-4781-8796-7fdcedfc9d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geopandas has version 0.13.2\n",
      "Movingpandas has version 0.17.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import movingpandas as mpd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "import time\n",
    "from scipy.sparse import coo_matrix\n",
    "from shapely.geometry import Point, LineString, MultiLineString\n",
    "from shapely import ops\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import neptune\n",
    "import folium\n",
    "import pickle\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Geopandas has version {}\".format(gpd.__version__))\n",
    "print(\"Movingpandas has version {}\".format(mpd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47dfe936-563b-42f5-8210-00bdf6c16e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add paths for modules\n",
    "sys.path.append('../src/models')\n",
    "sys.path.append('../src/visualization')\n",
    "sys.path.append('../src/features')\n",
    "# import modules\n",
    "import visualize\n",
    "import geometry_utils\n",
    "from maritime_traffic_network import MaritimeTrafficNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2fa99a-a277-40f3-bc38-25f03f9e53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for network creation\n",
    "# read data from file\n",
    "datasize = 'full'\n",
    "location = 'tromso'\n",
    "data_date = '202204'\n",
    "eval_date = '202205'\n",
    "\n",
    "orig_filename = '../data/processed/'+data_date+'_points_'+location+'_cleaned_meta_'+datasize+'_dualSplit_2.parquet'\n",
    "gdf = gpd.read_parquet(orig_filename)\n",
    "# Transform to desired CRS\n",
    "# 4326 for WGS 84 (global) // 32632 for UTM 32N (Norway)\n",
    "crs = 32632  # Coordinate reference system\n",
    "gdf.to_crs(crs, inplace=True)  # Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c293a7-bd98-4c57-8db5-b20b4f721d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load evaluation data\n",
    "eval_file = eval_date+'_points_'+location+'_cleaned_meta_full_dualSplit_2'\n",
    "filename = '../data/processed/' + eval_file + '.parquet'\n",
    "test_gdf = gpd.read_parquet(filename)\n",
    "crs = 32632  # Coordinate reference system\n",
    "test_gdf.to_crs(crs, inplace=True)  # Transformation\n",
    "all_test_trajectories = mpd.TrajectoryCollection(test_gdf, traj_id_col='mmsi', obj_id_col='mmsi')\n",
    "\n",
    "# select evaluation data\n",
    "selection_start = 1\n",
    "selection_end = len(all_test_trajectories)\n",
    "selection_step = 3\n",
    "selection = np.arange(selection_start, selection_end, selection_step)\n",
    "n_trajectories = len(selection)\n",
    "mmsis = test_gdf.mmsi.unique()[selection]\n",
    "test_trajectories = all_test_trajectories.filter('mmsi', mmsis.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a5377a-4fe0-40d2-9348-47a609380534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load significant points\n",
    "#sp_gdf = gpd.read_parquet('../data/processed/202204_significant_points_DP10_stavanger_full_UTM.parquet')\n",
    "#sp_gdf.to_crs(crs, inplace=True)  # Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c3b5eb-5d96-4d72-bcc1-0820042fe60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/jandrik91/Maritime-Traffic-Network/e/MAR-329\n",
      "Number of AIS messages: 5422129\n",
      "Number of trajectories: 14375\n",
      "Coordinate Reference System (CRS): EPSG:32632\n",
      "Calculating significant turning points with Douglas Peucker algorithm (tolerance = 10) ...\n",
      "Number of significant points detected: 399401 (7.37% of AIS messages)\n",
      "Time elapsed: 8.15 minutes\n",
      "Adding course over ground before and after each turn ...\n",
      "Done. Time elapsed: 9.97 minutes\n",
      "Calculating waypoints with HDBSCAN (min_samples = 10) ...\n",
      "Distance metric: mahalanobis\n",
      "3909 clusters detected\n",
      "Time elapsed: 37.12 minutes\n",
      "Constructing maritime traffic network graph from waypoints and trajectories...\n",
      "Progress: 10%...20%...30%...40%...50%...60%...70%...80%...90%...Done!\n",
      "------------------------\n",
      "Unpruned Graph:\n",
      "Number of nodes: 3909 (62 isolated)\n",
      "Number of edges: 21245\n",
      "Network is (weakly) connected: False\n",
      "------------------------\n",
      "Time elapsed: 44.91 minutes\n",
      "Pruning...\n",
      "------------------------\n",
      "Pruned Graph:\n",
      "Number of nodes: 3840 (33 isolated)\n",
      "Number of edges: 20105\n",
      "------------------------\n",
      "Evaluating graph on 752 trajectories\n",
      "Progress: 10%...20%...30%..."
     ]
    }
   ],
   "source": [
    "# make experiments\n",
    "vals_ms = [35, 30, 25, 20, 18, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6]\n",
    "vals_DP = []\n",
    "vals_v34 = []\n",
    "vals_v5 = []\n",
    "vals_max_dist = []\n",
    "vals_max_angle = []\n",
    "\n",
    "\n",
    "for i in range (0, len(vals_ms)):\n",
    "    run = neptune.init_run(\n",
    "        project=\"jandrik91/Maritime-Traffic-Network\",\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxYmQzMjgwZS1jZGYwLTQ2YjktYWNjOS02MjBlZWEzNzUzNDcifQ==\",\n",
    "    )  # your credentials\n",
    "\n",
    "    network = MaritimeTrafficNetwork(gdf, crs)\n",
    "    network.get_trajectories_info()\n",
    "    \n",
    "    # parameters\n",
    "    tolerance = 10 # DP tolerance parameter 0.0002\n",
    "    method = 'HDBSCAN'      # 'DBSCAN' , 'HDBSCAN', 'OPTICS'\n",
    "    metric = 'mahalanobis'  # 'euclidean', 'mahalanobis', 'haversine'\n",
    "    min_samples = vals_ms[i]\n",
    "    min_cluster_size = vals_ms[i]\n",
    "    eps = 0\n",
    "    V = np.diag([1, 1, 0.01, 0.01, 5e-4])  # mahalanobis distance parameter matrix V = np.diag([1, 1, 0.01, 0.01, 5e-4])  seems to be good\n",
    "    max_distance = 10\n",
    "    max_angle = 45\n",
    "    merge_stops = True\n",
    "    merge_stops_speed = 2\n",
    "    pruning = 1\n",
    "    model = data_date+'_waypoints_DP' + str(tolerance) + '_' + method + str(min_samples) +'_'+location+'_'+datasize+'_UTM'\n",
    "    # save hyperparameters\n",
    "    params = {\n",
    "        'Data':orig_filename,\n",
    "        'DP_tolerance':tolerance,\n",
    "        'clustering_method':method,\n",
    "        'clustering_metric':metric,\n",
    "        'clustering_min_samples':min_samples,\n",
    "        'clustering_min_cluster_size':min_cluster_size,\n",
    "        'clustering_eps':eps,\n",
    "        'clustering_metric_V':V,\n",
    "        'graph_generation_max_distance':max_distance,\n",
    "        'graph_generation_max_angle':max_angle\n",
    "    }\n",
    "    network.set_hyperparameters(params)\n",
    "    \n",
    "    # calculate significant turning points using Douglas Peucker algorithm\n",
    "    network.calc_significant_points_DP(tolerance)\n",
    "    #network.init_precomputed_significant_points(sp_gdf)\n",
    "    \n",
    "    # compute waypoints\n",
    "    network.calc_waypoints_clustering(method=method, min_samples=min_samples, min_cluster_size=min_cluster_size,\n",
    "                                      eps=eps, metric=metric, V=V)\n",
    "    # make graph from waypoints\n",
    "    network.make_graph_from_waypoints(max_distance=max_distance, max_angle=max_angle)\n",
    "    \n",
    "    # merge stop points\n",
    "    if merge_stops:\n",
    "        network.merge_stop_points(max_speed=merge_stops_speed)\n",
    "    \n",
    "    # prune graph\n",
    "    network.prune_graph(pruning)\n",
    "\n",
    "    # evaluate\n",
    "    all_paths, all_evaluation_results, summary, fig = network.evaluate_graph(test_trajectories)\n",
    "\n",
    "    # save experiment\n",
    "    run[\"model\"]=model\n",
    "    run[\"algorithm\"]='V4.0'\n",
    "    run[\"n_points\"]=len(network.gdf)\n",
    "    run[\"n_nodes\"]=network.G_pruned.number_of_nodes()\n",
    "    run[\"n_edges\"]=network.G_pruned.number_of_edges()\n",
    "    run[\"n_isolated\"]=nx.number_of_isolates(network.G_pruned)\n",
    "    run[\"merge_stops\"] = merge_stops\n",
    "    run[\"merge_stops_speed\"] = merge_stops_speed\n",
    "    run[\"pruning\"] = pruning\n",
    "    \n",
    "    params = network.hyperparameters\n",
    "    params['clustering_metric_V_coord'] = params['clustering_metric_V'][0][0]\n",
    "    params['clustering_metric_V_cog'] = params['clustering_metric_V'][2][2]\n",
    "    params['clustering_metric_V_speed'] = params['clustering_metric_V'][4][4]\n",
    "    run[\"parameters\"] = params\n",
    "    \n",
    "    run[\"test_data\"] = {'eval_file':eval_file,\n",
    "                        'selection_start':selection_start,\n",
    "                        'selection_end':selection_end,\n",
    "                        'selection_step':selection_step,\n",
    "                        'n_trajectories':n_trajectories}\n",
    "    \n",
    "    run[\"plot\"].upload(fig)\n",
    "    run[\"summary\"] = summary\n",
    "    \n",
    "    run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea502aa0-df65-4f8b-b672-de2c528d4d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save network as pickle object\n",
    "#fileObj = open('../data/interim/202204_waypoints_DP10_HDBSCAN15_stavanger_full_UTM.obj', 'wb')\n",
    "#pickle.dump(network, fileObj)\n",
    "#fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e05175-05f5-43e8-89ae-763f8d99146d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
