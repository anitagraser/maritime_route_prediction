{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77403721-0f74-4781-8796-7fdcedfc9d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geopandas has version 0.13.2\n",
      "Movingpandas has version 0.17.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import movingpandas as mpd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "import time\n",
    "from scipy.sparse import coo_matrix\n",
    "from shapely.geometry import Point, LineString, MultiLineString\n",
    "from shapely import ops\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import neptune\n",
    "import folium\n",
    "import pickle\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Geopandas has version {}\".format(gpd.__version__))\n",
    "print(\"Movingpandas has version {}\".format(mpd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47dfe936-563b-42f5-8210-00bdf6c16e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add paths for modules\n",
    "sys.path.append('../src/models')\n",
    "sys.path.append('../src/visualization')\n",
    "sys.path.append('../src/features')\n",
    "# import modules\n",
    "import visualize\n",
    "import geometry_utils\n",
    "from maritime_traffic_network import MaritimeTrafficNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2fa99a-a277-40f3-bc38-25f03f9e53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for network creation\n",
    "# read data from file\n",
    "datasize = '2M'\n",
    "orig_filename = '../data/processed/202204_points_stavanger_cleaned_meta_'+datasize+'_dualSplit_2.parquet'\n",
    "gdf = gpd.read_parquet(orig_filename)\n",
    "# Transform to desired CRS\n",
    "# 4326 for WGS 84 (global) // 32632 for UTM 32N (Norway)\n",
    "crs = 32632  # Coordinate reference system\n",
    "gdf.to_crs(crs, inplace=True)  # Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c293a7-bd98-4c57-8db5-b20b4f721d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load evaluation data\n",
    "eval_file = '202205_points_stavanger_cleaned_meta_full_dualSplit_2'\n",
    "filename = '../data/processed/' + eval_file + '.parquet'\n",
    "test_gdf = gpd.read_parquet(filename)\n",
    "crs = 32632  # Coordinate reference system\n",
    "test_gdf.to_crs(crs, inplace=True)  # Transformation\n",
    "all_test_trajectories = mpd.TrajectoryCollection(test_gdf, traj_id_col='mmsi', obj_id_col='mmsi')\n",
    "\n",
    "# select evaluation data\n",
    "selection_start = 0\n",
    "selection_end = len(all_test_trajectories)\n",
    "selection_step = 20\n",
    "selection = np.arange(selection_start, selection_end, selection_step)\n",
    "n_trajectories = len(selection)\n",
    "mmsis = test_gdf.mmsi.unique()[selection]\n",
    "test_trajectories = all_test_trajectories.filter('mmsi', mmsis.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9c3b5eb-5d96-4d72-bcc1-0820042fe60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/jandrik91/Maritime-Traffic-Network/e/MAR-165\n",
      "Number of AIS messages: 1794132\n",
      "Number of trajectories: 4666\n",
      "Coordinate Reference System (CRS): EPSG:32632\n",
      "Calculating significant turning points with Douglas Peucker algorithm (tolerance = 10) ...\n",
      "Number of significant points detected: 134855 (7.52% of AIS messages)\n",
      "Time elapsed: 1.38 minutes\n",
      "Adding course over ground before and after each turn ...\n",
      "Done. Time elapsed: 0.87 minutes\n",
      "Calculating waypoints with HDBSCAN (min_samples = 10) ...\n",
      "Distance metric: mahalanobis\n",
      "1770 clusters detected\n",
      "Time elapsed: 2.98 minutes\n",
      "Constructing maritime traffic network graph from waypoints and trajectories...\n",
      "Progress: 10%...20%...30%...40%...50%...60%...70%...80%...90%..."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m network\u001b[38;5;241m.\u001b[39mcalc_waypoints_clustering(method\u001b[38;5;241m=\u001b[39mmethod, min_samples\u001b[38;5;241m=\u001b[39mmin_samples, min_cluster_size\u001b[38;5;241m=\u001b[39mmin_cluster_size,\n\u001b[1;32m     59\u001b[0m                                   eps\u001b[38;5;241m=\u001b[39meps, metric\u001b[38;5;241m=\u001b[39mmetric, V\u001b[38;5;241m=\u001b[39mV)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# make graph from waypoints\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_graph_from_waypoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_distance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_angle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_angle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# merge stop points\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_stops:\n",
      "File \u001b[0;32m~/maritime_route_prediction/notebooks/../src/models/maritime_traffic_network.py:456\u001b[0m, in \u001b[0;36mMaritimeTrafficNetwork.make_graph_from_waypoints\u001b[0;34m(self, max_distance, max_angle)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpercentage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%...\u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# store adjacency matrix as sparse matrix in COO format\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m row_indices, col_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mcoord_dict\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    457\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(coord_dict\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    458\u001b[0m A \u001b[38;5;241m=\u001b[39m coo_matrix((values, (row_indices, col_indices)), shape\u001b[38;5;241m=\u001b[39m(n_clusters, n_clusters))\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "# make experiments\n",
    "vals_ms = []\n",
    "vals_DP = []\n",
    "vals_v34 = []\n",
    "vals_v5 = []\n",
    "vals_max_dist = [1, 20, 50, 100, 200,\n",
    "                 1, 10, 20, 50, 100, 200,\n",
    "                 1, 10, 20, 50, 100, 200,\n",
    "                 1, 10, 20, 50, 100, 200]\n",
    "vals_max_angle = [45, 45, 45, 45, 45,\n",
    "                 30, 30, 30, 30, 30, 30,\n",
    "                 20, 20, 20, 20, 20, 20,\n",
    "                 60, 60, 60, 60, 60, 60]\n",
    "\n",
    "\n",
    "for i in range (0, len(vals_max_dist)):\n",
    "    run = neptune.init_run(\n",
    "        project=\"jandrik91/Maritime-Traffic-Network\",\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxYmQzMjgwZS1jZGYwLTQ2YjktYWNjOS02MjBlZWEzNzUzNDcifQ==\",\n",
    "    )  # your credentials\n",
    "\n",
    "    network = MaritimeTrafficNetwork(gdf, crs)\n",
    "    network.get_trajectories_info()\n",
    "    \n",
    "    # parameters\n",
    "    tolerance = 10 # DP tolerance parameter 0.0002\n",
    "    method = 'HDBSCAN'      # 'DBSCAN' , 'HDBSCAN', 'OPTICS'\n",
    "    metric = 'mahalanobis'  # 'euclidean', 'mahalanobis', 'haversine'\n",
    "    min_samples = 10\n",
    "    min_cluster_size = 10\n",
    "    eps = 0\n",
    "    V = np.diag([1, 1, 0.01, 0.01, 5e-4])  # mahalanobis distance parameter matrix V = np.diag([1, 1, 0.01, 0.01, 5e-4])  seems to be good\n",
    "    max_distance = vals_max_dist[i]\n",
    "    max_angle = vals_max_angle[i]\n",
    "    merge_stops = True\n",
    "    merge_stops_speed = 2\n",
    "    pruning = 1\n",
    "    model = '202204_waypoints_DP' + str(tolerance) + '_' + method + str(min_samples) +'_stavanger_'+datasize+'_UTM'\n",
    "    # save hyperparameters\n",
    "    params = {\n",
    "        'Data':orig_filename,\n",
    "        'DP_tolerance':tolerance,\n",
    "        'clustering_method':method,\n",
    "        'clustering_metric':metric,\n",
    "        'clustering_min_samples':min_samples,\n",
    "        'clustering_min_cluster_size':min_cluster_size,\n",
    "        'clustering_eps':eps,\n",
    "        'clustering_metric_V':V,\n",
    "        'graph_generation_max_distance':max_distance,\n",
    "        'graph_generation_max_angle':max_angle\n",
    "    }\n",
    "    network.set_hyperparameters(params)\n",
    "    \n",
    "    # calculate significant turning points using Douglas Peucker algorithm\n",
    "    network.calc_significant_points_DP(tolerance)\n",
    "    \n",
    "    # compute waypoints\n",
    "    network.calc_waypoints_clustering(method=method, min_samples=min_samples, min_cluster_size=min_cluster_size,\n",
    "                                      eps=eps, metric=metric, V=V)\n",
    "    # make graph from waypoints\n",
    "    network.make_graph_from_waypoints(max_distance=max_distance, max_angle=max_angle)\n",
    "    \n",
    "    # merge stop points\n",
    "    if merge_stops:\n",
    "        network.merge_stop_points(max_speed=merge_stops_speed)\n",
    "    \n",
    "    # prune graph\n",
    "    network.prune_graph(pruning)\n",
    "\n",
    "    # evaluate\n",
    "    all_paths, all_evaluation_results, summary, fig = network.evaluate_graph(test_trajectories)\n",
    "\n",
    "    # save experiment\n",
    "    run[\"model\"]=model\n",
    "    run[\"n_points\"]=len(network.gdf)\n",
    "    run[\"n_nodes\"]=network.G_pruned.number_of_nodes()\n",
    "    run[\"n_edges\"]=network.G_pruned.number_of_edges()\n",
    "    run[\"n_isolated\"]=nx.number_of_isolates(network.G_pruned)\n",
    "    run[\"merge_stops\"] = merge_stops\n",
    "    run[\"merge_stops_speed\"] = merge_stops_speed\n",
    "    run[\"pruning\"] = pruning\n",
    "    \n",
    "    params = network.hyperparameters\n",
    "    params['clustering_metric_V_coord'] = params['clustering_metric_V'][0][0]\n",
    "    params['clustering_metric_V_cog'] = params['clustering_metric_V'][2][2]\n",
    "    params['clustering_metric_V_speed'] = params['clustering_metric_V'][4][4]\n",
    "    run[\"parameters\"] = params\n",
    "    \n",
    "    run[\"test_data\"] = {'eval_file':eval_file,\n",
    "                        'selection_start':selection_start,\n",
    "                        'selection_end':selection_end,\n",
    "                        'selection_step':selection_step,\n",
    "                        'n_trajectories':n_trajectories}\n",
    "    \n",
    "    run[\"plot\"].upload(fig)\n",
    "    run[\"summary\"] = summary\n",
    "    \n",
    "    run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea502aa0-df65-4f8b-b672-de2c528d4d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save network as pickle object\n",
    "#fileObj = open('../data/interim/202204_waypoints_DP10_HDBSCAN15_stavanger_full_UTM.obj', 'wb')\n",
    "#pickle.dump(network, fileObj)\n",
    "#fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e05175-05f5-43e8-89ae-763f8d99146d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
