{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fca4943-219f-456b-85c0-5588770889c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import movingpandas as mpd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "import time\n",
    "from scipy.sparse import coo_matrix\n",
    "from shapely.geometry import Point, LineString\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Geopandas has version {}\".format(gpd.__version__))\n",
    "print(\"Movingpandas has version {}\".format(mpd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7486614e-4bef-4093-b720-59efded31efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add paths for modules\n",
    "sys.path.append('../src/models')\n",
    "sys.path.append('../src/visualization')\n",
    "sys.path.append('../src/features')\n",
    "# import modules\n",
    "import visualize\n",
    "import geometry_utils\n",
    "from maritime_traffic_network import MaritimeTrafficNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1141c88-9ab6-474e-8ab1-549fd40e1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw data from file\n",
    "filename = '../data/processed/202204_points_stavanger_cleaned_meta_500k_dualSplit.parquet'\n",
    "gdf = gpd.read_parquet(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a676122-a6a8-4cc2-8612-250f14bf48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to desired CRS\n",
    "# 4326 for WGS 84 (global) // 32632 for UTM 32N (Norway)\n",
    "crs = 32632  # Coordinate reference system\n",
    "gdf.to_crs(crs, inplace=True)  # Transformation\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490fd86f-d727-407d-9ad5-3156aedf2696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize maritime traffic network\n",
    "network = MaritimeTrafficNetwork(gdf, crs)\n",
    "network.get_trajectories_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ab6bf4-32fb-47e8-bb0b-a6132da4c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute Douglas Peucker significant points\n",
    "network.calc_significant_points_DP(tolerance=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9647c8e-8430-480b-803f-6ab6825f2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect waypoints using spatial clustering\n",
    "method = 'HDBSCAN'      # 'DBSCAN' , 'HDBSCAN', 'OPTICS'\n",
    "metric = 'mahalanobis'  # 'euclidean', 'mahalanobis', 'haversine'\n",
    "min_samples = 10\n",
    "min_cluster_size = 10\n",
    "eps = 0.02\n",
    "V = np.diag([1, 1, 0.01, 0.01, 1e-5])  # mahalanobis distance parameter matrix V = np.diag([0.01, 0.01, 1e6, 1e6]) \n",
    "network.calc_waypoints_clustering(method=method, min_samples=min_samples, min_cluster_size=min_cluster_size,\n",
    "                                  eps=eps, metric=metric, V=V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce0ccfd-9652-4e01-85ef-a5330b834ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build network\n",
    "#network.make_graph_from_waypoints(min_passages=2)\n",
    "start = time.time()\n",
    "n_clusters = len(network.waypoints)\n",
    "coord_dict = {}\n",
    "wps = network.waypoints.copy()\n",
    "wps.set_geometry('convex_hull', inplace=True)\n",
    "# for each trajectory, find the distance to all waypoints\n",
    "for mmsi in network.significant_points.mmsi.unique():\n",
    "    # find all intersections and close passages of waypoints\n",
    "    trajectory = network.significant_points_trajectory.get_trajectory(mmsi)\n",
    "    trajectory_segments = trajectory.to_line_gdf()\n",
    "    distances = trajectory.distance(wps.convex_hull)\n",
    "    mask = distances<10\n",
    "    close_wps = wps[mask]\n",
    "    # find temporal order  of waypoint passage\n",
    "    passages = []\n",
    "    for i in range(0, len(trajectory_segments)):\n",
    "        segment = trajectory_segments.iloc[i]\n",
    "        # distance of each segment to the selection of close waypoints\n",
    "        distance_to_line = segment['geometry'].distance(close_wps.convex_hull)  # distance between line segment and waypoint convex hull     \n",
    "        distance_to_origin = segment['geometry'].boundary.geoms[0].distance(close_wps.geometry)  # distance between first point of segment and waypoint centroids (needed for sorting)\n",
    "        close_wps['distance_to_line'] = distance_to_line.tolist()\n",
    "        close_wps['distance_to_origin'] = distance_to_origin.tolist()\n",
    "        # angle between line segment and mean traffic direction in each waypoint\n",
    "        close_wps['angle'] = np.abs(geometry_utils.compass_mean(close_wps['cog_before'], close_wps['cog_after']) - segment['direction'])  \n",
    "        # the line segment is associated with the waypoint, when its distance and angle is less than a threshold\n",
    "        passed_wps = close_wps[(close_wps['distance_to_line']<10) & (close_wps['angle']<45)]\n",
    "        passed_wps.sort_values(by='distance_to_origin', inplace=True)\n",
    "        passages.extend(passed_wps['clusterID'].tolist())\n",
    "    \n",
    "    # create edges between subsequent passed waypoints\n",
    "    if len(passages) > 1:  # subset needs to contain at least 2 waypoints\n",
    "        for i in range(0, len(passages)-1):\n",
    "            row = passages[i]\n",
    "            col = passages[i+1]\n",
    "            if row != col:  # no self loops\n",
    "                if ((row==184) & (col==181)):\n",
    "                    print(mmsi)\n",
    "                if (row, col) in coord_dict:\n",
    "                    coord_dict[(row, col)] += 1  # increase the edge weight for each passage\n",
    "                else:\n",
    "                    coord_dict[(row, col)] = 1  # create edge if it does not exist yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cfb82c-7a4e-4d04-bcfb-64197f1fce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store adjacency matrix as sparse matrix in COO format\n",
    "row_indices, col_indices = zip(*coord_dict.keys())\n",
    "values = list(coord_dict.values())\n",
    "A = coo_matrix((values, (row_indices, col_indices)), shape=(n_clusters, n_clusters))\n",
    "\n",
    "# Construct a GeoDataFrame from graph edges\n",
    "waypoints = network.waypoints.copy()\n",
    "waypoints.set_geometry('geometry', inplace=True, crs=network.crs)\n",
    "waypoint_connections = pd.DataFrame(columns=['from', 'to', 'geometry', 'direction', 'passages'])\n",
    "for orig, dest, weight in zip(A.row, A.col, A.data):\n",
    "    # add linestring as edge\n",
    "    p1 = waypoints[waypoints.clusterID == orig].geometry\n",
    "    p2 = waypoints[waypoints.clusterID == dest].geometry\n",
    "    edge = LineString([(p1.x, p1.y), (p2.x, p2.y)])\n",
    "    # compute the orientation fo the edge (COG)\n",
    "    p1 = Point(waypoints[waypoints.clusterID == orig].lon, waypoints[waypoints.clusterID == orig].lat)\n",
    "    p2 = Point(waypoints[waypoints.clusterID == dest].lon, waypoints[waypoints.clusterID == dest].lat)\n",
    "    direction = geometry_utils.calculate_initial_compass_bearing(p1, p2)\n",
    "    line = pd.DataFrame([[orig, dest, edge, direction, weight]], \n",
    "                        columns=['from', 'to', 'geometry', 'direction', 'passages'])\n",
    "    waypoint_connections = pd.concat([waypoint_connections, line])\n",
    "waypoint_connections = gpd.GeoDataFrame(waypoint_connections, geometry='geometry', crs=network.crs)\n",
    "end = time.time()\n",
    "print(f'Time elapsed: {(end-start)/60:.2f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920454b2-6e1e-4b3e-819f-928777f3a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_scipy_sparse_array(A, create_using=nx.DiGraph)\n",
    "\n",
    "# add node features\n",
    "for i in range(0, len(waypoints)):\n",
    "    node_id = waypoints.clusterID.iloc[i]\n",
    "    G.nodes[node_id]['n_members'] = waypoints.n_members.iloc[i]\n",
    "    G.nodes[node_id]['position'] = (waypoints.lon.iloc[i], waypoints.lat.iloc[i])  # !changed lat-lon to lon-lat for plotting\n",
    "    G.nodes[node_id]['speed'] = waypoints.speed.iloc[i]\n",
    "    G.nodes[node_id]['cog_before'] = waypoints.cog_before.iloc[i]\n",
    "    G.nodes[node_id]['cog_after'] = waypoints.cog_after.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e2a99-b73a-4e72-93cb-6435ce489d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmsi = ['219347000_4_2022-04-03 01:38:48', '219348000_0_2022-04-02 01:42:01', '305981000_0_2022-04-02 11:03:05']\n",
    "#trajectory = network.trajectories.get_trajectory(mmsi)\n",
    "#DP_trajectory = network.significant_points_trajectory.get_trajectory(mmsi)\n",
    "DP_points = network.significant_points[network.significant_points.mmsi.isin(mmsi)]\n",
    "DP_trajectories = network.significant_points_trajectory.to_traj_gdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae41b00-4836-4801-b98a-4c1f48a399cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster_list=[357, 358, 389, 478, 389, 477, 478, 477, 478, 477, 510, 511, 373, 430, 427, 429, 430, 461, 462, 459, 460, 462, 474, 473, 474, 475, 473, 483, 494, 494, 494, 495, 597, 597, 597, 598, \n",
    "#              599, 600, 598, 599, 600, 152, 153, 598, 599, 600, 604, 605, 152, 153, 604, 605, 153, 504, 605]\n",
    "#wpts = network.waypoints.copy()\n",
    "#wpts.set_geometry('convex_hull', inplace=True, crs=network.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df2fc9-7987-45ae-a2be-342370cc0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "map = network.map_waypoints()\n",
    "map = waypoint_connections[waypoint_connections.passages>1].explore(m=map)\n",
    "#map = network.map_graph(pruned=True)\n",
    "#map = visualize.map_accurate_and_simplified_trajectory(trajectory, DP_trajectory, map=map)\n",
    "map = DP_trajectories[DP_trajectories.mmsi.isin(mmsi)][['geometry', 'mmsi']].explore(m=map, color='black')\n",
    "map = DP_points[DP_points.clusterID >= 0][['geometry', 'clusterID', 'mmsi']].explore(m=map, color='pink')\n",
    "#map = wpts[wpts.clusterID.isin(cluster_list)][['convex_hull', 'clusterID']].explore(m=map, name='passed clusters', legend=False,\n",
    "#                                              style_kwds={'color':'yellow', 'fillColor':'yellow', 'fillOpacity':0.2})\n",
    "folium.LayerControl().add_to(map)\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded8137d-d041-40c0-ae7d-696f40b8c811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
